import os
import requests
from datetime import datetime

DEBUG_LOG_FILE = "gpt_summary_debug.txt"

NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
DB_JOURNAL = os.environ.get("DB_JOURNAL")

def log_debug(text):
    with open(DEBUG_LOG_FILE, "a", encoding="utf-8") as f:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        f.write(f"[{timestamp}] {text}\n")

def get_latest_journal_entry():
    url = f"https://api.notion.com/v1/databases/{DB_JOURNAL}/query"
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": "2022-06-28",
        "Content-Type": "application/json",
    }
    payload = {
        "sorts": [{"property": "Date", "direction": "descending"}],
        "page_size": 1
    }
    res = requests.post(url, json=payload, headers=headers)
    res.raise_for_status()
    results = res.json().get("results", [])
    return results[0] if results else None

def extract_rollup_text(entry, property_name):
    if property_name not in entry["properties"]:
        print(f"âš ï¸ Feld nicht gefunden: '{property_name}'")
        return ""

    prop = entry["properties"][property_name]
    if prop.get("type") == "rollup":
        rollup = prop.get("rollup", {})
        if rollup.get("type") == "array":
            return ", ".join([
                v.get("plain_text")
                or v.get("name")
                or v.get("text", {}).get("content", "")
                or v.get("title", [{}])[0].get("text", {}).get("content", "")
                for v in rollup.get("array", [])
            ])
        elif rollup.get("type") == "number":
            return str(rollup.get("number", ""))
        elif rollup.get("type") == "rich_text":
            return " ".join([
                rt.get("text", {}).get("content", "") for rt in rollup.get("rich_text", [])
            ])
    elif prop.get("type") == "multi_select":
        return ", ".join([v.get("name", "") for v in prop.get("multi_select", [])])
    elif prop.get("type") == "rich_text":
        return " ".join([
            rt.get("text", {}).get("content", "") for rt in prop.get("rich_text", [])
        ])
    elif prop.get("type") == "relation":
        return ", ".join([r.get("id", "") for r in prop.get("relation", [])])
    return ""

def generate_prompt(entry, date_str):
    return f"""Zusammenfassung fÃ¼r den {date_str}:
Nutze diese Informationen fÃ¼r den Eintrag:

ğŸ“Œ Projekte: {extract_rollup_text(entry, "Projects")}
ğŸ“Œ Bereiche/Ressourcen: {extract_rollup_text(entry, "Areas/Resources")}

ğŸ”– Kategorien (Tasks): {extract_rollup_text(entry, "kategorien tasks")}
ğŸ”– Kategorien (Notes): {extract_rollup_text(entry, "kategorien notes")}
ğŸ· Tags (Notes): {extract_rollup_text(entry, "notes-tags")}
ğŸ“‚ Typen (Notes): {extract_rollup_text(entry, "notes-typ")}

ğŸ§¾ Beschreibung Projekte: {extract_rollup_text(entry, "Projectdescription")}
ğŸ§¾ Beschreibung Areas/Resources: {extract_rollup_text(entry, "Areasdescription")}

âœ… Erledigte Tasks: {extract_rollup_text(entry, "Done")} % erledigt von der Gesamtanzahl der relevanten fÃ¼r diesen Tag.

â¤ Gib eine klare Zusammenfassung mit folgenden Schwerpunkten:
- Woran wurde inhaltlich gearbeitet?
- Gab es erkennbare thematische HÃ¤ufungen?
- Welche Learnings, Trends oder Empfehlungen lassen sich aus der AktivitÃ¤t ableiten?
- Gliedere in kurze AbsÃ¤tze, kein Bullet-Point-Stil.
- Keine Wiederholung einzelner Titel, nur thematische Auswertung."""

def main():
    entry = get_latest_journal_entry()
    if not entry:
        print("âŒ Kein Journaleintrag gefunden.")
        log_debug("âŒ Kein Journaleintrag gefunden.")
        return

    date_str = entry["properties"].get("Date", {}).get("date", {}).get("start", "Kein Datum")

    print("\nâœ… Generierter GPT-Eingabe-Prompt:\n")
    prompt = generate_prompt(entry, date_str)
    print(prompt)
    print("\nğŸ” Fertig. Alle verwendeten Notion-Werte wurden ausgelesen.")

if __name__ == "__main__":
    main()
